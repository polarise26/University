{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Project notebook.\n",
    "---\n",
    "\n",
    "This is my demonstration of understanding of Units 4, and 5 in CL-NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted by Karan Taneja |\n",
      "SAP ID: 500084399 | Batch: 5, AIML (H)\n"
     ]
    }
   ],
   "source": [
    "print(\"Submitted by Karan Taneja |\\nSAP ID: 500084399 | Batch: 5, AIML (H)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit - 4: Applications of NLP\n",
    "\n",
    "## Information retrieval."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in NLP.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to demonstrate Information Retrieval:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we define a collection of documents, a query, and use the TF-IDF algorithm to compute the similarity between the query and the documents. \n",
    "\n",
    "And simultaneously, I'll cover the steps involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Acquisition: The first step in any NLP task is to acquire the relevant data. In IR, this may involve crawling websites, scraping data from social media platforms, or accessing structured datasets such as news articles or scientific publications.\n",
    "\n",
    "Here, the dataset is directly provided, so no acquisition is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a collection of documents\n",
    "docs = [\n",
    "    'The quick brown fox jumps over the lazy dog',\n",
    "    'The dog chased the cat',\n",
    "    'The cat climbed a tree',\n",
    "    'A bird in the hand is worth two in the bush',\n",
    "    'Time flies like an arrow; fruit flies like a banana'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing: After preprocessing, the text data is typically indexed for efficient retrieval. This involves creating an inverted index that maps terms to the documents that contain them, as well as other metadata such as document frequency and term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer and transform the documents\n",
    "tfidf = TfidfVectorizer()\n",
    "doc_vectors = tfidf.fit_transform(docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Processing: When a user submits a query, it needs to be processed to identify the relevant terms and to generate a ranked list of documents that match the query. Here, we're using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query = 'dog'\n",
    "\n",
    "# Transform the query into a vector\n",
    "query_vector = tfidf.transform([query])\n",
    "\n",
    "# Compute cosine similarity between the query vector and the document vectors\n",
    "similarity = cosine_similarity(query_vector, doc_vectors)[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval: Using the index and query processing techniques, the system retrieves a ranked list of documents that are most relevant to the user's query. Here, we're using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the documents by descending order of similarity\n",
    "indices = np.argsort(similarity)[::-1]\n",
    "scores = similarity[indices]\n",
    "documents = [docs[i] for i in indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.43\n",
      "Document: The dog chased the cat\n",
      "\n",
      "Similarity score: 0.29\n",
      "Document: The quick brown fox jumps over the lazy dog\n",
      "\n",
      "Similarity score: 0.00\n",
      "Document: Time flies like an arrow; fruit flies like a banana\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top 3 most similar documents\n",
    "for i in range(3):\n",
    "    print(f'Similarity score: {scores[i]:.2f}\\nDocument: {documents[i]}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a barebones IR system, based on TF-IDF, and cosine similarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of IR systems:\n",
    "\n",
    "Evaluation is a critical step in information retrieval (IR) to measure the performance of the IR system and to identify areas for improvement. There are several commonly used evaluation metrics in IR, including:\n",
    "\n",
    "1. Precision: Precision measures the proportion of retrieved documents that are relevant to the query. In other words, it answers the question: \"Of the documents that were retrieved, how many were actually relevant?\" A high precision score means that the system retrieves mostly relevant documents.\n",
    "\n",
    "2. Recall: Recall measures the proportion of relevant documents that are retrieved by the system. In other words, it answers the question: \"Of all the relevant documents, how many were retrieved?\" A high recall score means that the system retrieves most of the relevant documents.\n",
    "\n",
    "3. F1 score: The F1 score is the harmonic mean of precision and recall, and provides a balanced measure of both precision and recall. It ranges from 0 to 1, where a score of 1 indicates perfect precision and recall.\n",
    "\n",
    "4. Mean Average Precision (MAP): MAP measures the average precision of the system across multiple queries. It takes into account the order of the retrieved documents, and penalizes the system for returning irrelevant documents early in the ranking.\n",
    "\n",
    "To evaluate an IR system, a set of queries and corresponding relevant documents (known as a \"test collection\") is typically used. The IR system is then evaluated on its ability to retrieve the relevant documents for each query, and the evaluation metrics are computed and reported."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design features relevant for IR systems.\n",
    "\n",
    "1. **Indexing**: This is the process of creating an index of the documents to be searched. The index typically contains the words or terms that appear in the document, along with their frequency and location. The indexing process can involve techniques such as tokenization, stemming, and stopword removal.\n",
    "\n",
    "2. **Query processing**: This is the process of parsing and processing user queries to extract the relevant terms or keywords. Techniques such as query expansion and relevance feedback can be used to improve the quality of the query.\n",
    "\n",
    "3. **Ranking**: This is the process of ranking the documents in the index based on their relevance to the query. Techniques such as tf-idf weighting and BM25 can be used to assign a relevance score to each document.\n",
    "\n",
    "4. **User interface**: This is the interface that allows users to interact with the IRS. The user interface can include features such as search bars, filters, and sorting options.\n",
    "\n",
    "5. **Scalability**: The IRS should be able to handle large volumes of data and queries efficiently. Techniques such as distributed indexing and query processing can be used to improve scalability.\n",
    "\n",
    "6. **Evaluation**: The IRS should be evaluated using appropriate metrics to measure its effectiveness and identify areas for improvement. Common evaluation metrics include precision, recall, F1 score, MAP, and NDCG.\n",
    "\n",
    "7. **Adaptivity**: The IRS should be able to adapt to changes in the data or user behavior. Techniques such as machine learning and natural language processing can be used to improve adaptivity.\n",
    "\n",
    "8. **Security**: The IRS should have appropriate security measures in place to protect sensitive data and user privacy. Techniques such as access control and encryption can be used to improve security."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Input data**: We start with a piece of text containing some information that we want to extract. For this example, let's say we have a string that contains some phone numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"Please contact us at 123-456-7890 or 555-555-5555.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Define regular expression pattern**: We need to define a regular expression pattern that will match the information we want to extract. In this case, we want to extract phone numbers in the format \"XXX-XXX-XXXX\", so we can use the following pattern:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\\d{3}-\\d{3}-\\d{4}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Compile regular expression**: We need to compile the regular expression pattern using the `re.compile()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(pattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Search for matches**: We can use the `re.findall()` function to search for all occurrences of the regular expression pattern in the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = regex.findall(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Output extracted information**: We can output the extracted information to the console, or to a file, or store it in a variable for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-456-7890', '555-555-5555']\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of IE:\n",
    "\n",
    "Information extraction (IE) has many practical applications across a wide range of industries and domains. Here are some examples:\n",
    "\n",
    "1. **Business intelligence and analytics**: IE can be used to extract and analyze large amounts of unstructured data from sources such as emails, social media, and customer feedback, in order to identify trends, patterns, and insights that can inform business decision-making.\n",
    "\n",
    "2. **Healthcare**: IE can be used to extract structured data from medical records, such as patient demographics, diagnoses, and treatments, in order to improve clinical decision-making, patient outcomes, and healthcare management.\n",
    "\n",
    "3. **Legal and regulatory compliance**: IE can be used to extract and categorize legal and regulatory documents, such as contracts, policies, and financial reports, in order to identify compliance risks, monitor regulatory changes, and ensure regulatory compliance.\n",
    "\n",
    "4. **Information retrieval**: IE can be used to extract information from text documents in order to improve search results and relevance. For example, extracting key phrases and entities from a document can help improve the accuracy of search queries.\n",
    "\n",
    "5. **Content generation**: IE can be used to generate structured data that can be used to automatically create content such as summaries, abstracts, and headlines, which can be used to improve information discovery and consumption.\n",
    "\n",
    "These are just a few examples of the applications of information extraction. As the amount of unstructured data continues to grow across the internet, and emergence of Big Data, Deep Learning, and incredibly large models keeps its pace, it has become an extremely lucrative field to contribute to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report generation:\n",
    "\n",
    "Using NLP techniques to find the important and opinionated words within your documents. Here is a simple report generator for customer reviews for a restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 key themes and issues:\n",
      "- cozi (1)\n",
      "- staff (1)\n",
      "- dessert (1)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "# Load the customer reviews\n",
    "reviews = [\n",
    "    \"The food was excellent but the service was slow.\",\n",
    "    \"The atmosphere was cozy and the staff were friendly.\",\n",
    "    \"The prices were reasonable but the portions were small.\",\n",
    "    \"The cocktails were delicious but the noise level was too high.\",\n",
    "    \"The desserts were disappointing and the wait for a table was long.\"\n",
    "]\n",
    "\n",
    "# Define a function to preprocess the reviews\n",
    "def preprocess_review(review):\n",
    "    # Tokenize the review\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    # Remove stop words and punctuation\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english') and token.isalnum()]\n",
    "    # Stem the tokens\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    # Perform named entity recognition\n",
    "    named_entities = ne_chunk(nltk.pos_tag(tokens))\n",
    "    # Extract the named entities\n",
    "    named_entities = [' '.join(leaf[0] for leaf in tree.leaves()) for tree in named_entities if isinstance(tree, nltk.tree.Tree)]\n",
    "    # Extract the key phrases\n",
    "    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    key_phrases = []\n",
    "    tree = cp.parse(nltk.pos_tag(tokens))\n",
    "    for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        key_phrase = ' '.join(word for word, tag in subtree.leaves())\n",
    "        if len(key_phrase.split()) > 1:\n",
    "            key_phrases.append(key_phrase)\n",
    "    # Combine the named entities and key phrases\n",
    "    extracted_information = named_entities + key_phrases\n",
    "    # Return the preprocessed review\n",
    "    return ' '.join(extracted_information)\n",
    "\n",
    "# Preprocess the reviews\n",
    "preprocessed_reviews = [preprocess_review(review) for review in reviews]\n",
    "\n",
    "# Create a frequency distribution of the extracted information\n",
    "flat_information = [item for sublist in preprocessed_reviews for item in sublist.split()]\n",
    "freq_dist = nltk.FreqDist(flat_information)\n",
    "\n",
    "# Print the top 3 key themes and issues\n",
    "print(\"Top 3 key themes and issues:\")\n",
    "for item in freq_dist.most_common(3):\n",
    "    print(\"- {} ({})\".format(item[0], item[1]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 key themes raised by customers in reviews were about coziness, the staff, and the dessert. These may be key areas for the establishment owners to focus on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontology\n",
    "\n",
    "Ontology refers to a formal representation of knowledge or concepts in a particular domain. It defines the relationships between different concepts in a domain, and the properties or attributes of those concepts. An ontology can be thought of as a shared vocabulary or taxonomy that provides a structured way of representing knowledge in a domain, which can be used to support tasks such as information retrieval, question answering, and knowledge management.\n",
    "\n",
    "Ontologies are typically created by domain experts and knowledge engineers, who use formal languages such as the Web Ontology Language (OWL) to specify the relationships between concepts and properties. Ontologies can be represented in various formats, such as XML, RDF, and OWL, and can be stored and queried using ontology languages and tools.\n",
    "\n",
    "Ontologies have many applications in NLP, such as in semantic search, where an ontology can be used to represent the meanings of words and their relationships, and in natural language understanding, where an ontology can be used to map natural language expressions to formal representations of meaning. Ontologies are also used in various knowledge-intensive applications, such as expert systems, decision support systems, and knowledge management systems.\n",
    "\n",
    "An ontology can be thought of as a schema or a structured vocabulary for a particular domain. It specifies the concepts and relationships within a domain, and the properties and attributes of those concepts. In this way, an ontology provides a formal and structured way of representing knowledge that can be used to support various NLP applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Ontology:\n",
    "\n",
    "Before ontology; taxonomies, thesauri, and frames were popular, but none of them really fit the requirements of NLP in a more expressive and informal application. While these approaches are still used in some contexts, ontologies have become more popular in recent years due to their flexibility and expressiveness. Ontologies provide a more formal and structured way of representing knowledge, which makes it easier to integrate and reason about knowledge from different sources. Additionally, ontologies can be used to support a wide range of NLP applications, such as information retrieval, question answering, and semantic search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit - 5: Emerging Technologies in NLP\n",
    "---\n",
    "\n",
    "Here's an outline of a few technologies highlighted in the presentations:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multimedia presentation generation is the process of automatically creating a multimedia presentation from a set of input data, such as images, videos, and text. The goal is to generate a presentation that effectively communicates a message or tells a story to an audience.\n",
    "\n",
    "Information extraction and natural language processing techniques can be used to generate the content of the presentation, while computer vision and machine learning techniques can be used to select and arrange the multimedia components.\n",
    "\n",
    "Here is an example of how the process might work:\n",
    "\n",
    "1. Input data: The input data might include a set of images, videos, and text related to a particular topic or theme. For example, the input data might consist of images and text related to a news story or a scientific discovery.\n",
    "\n",
    "2. Content generation: Information extraction and natural language processing techniques can be used to analyze the input data and generate a script or outline for the presentation. This might involve identifying key concepts and themes, extracting important details and facts, and organizing the content into a coherent narrative structure.\n",
    "\n",
    "3. Multimedia selection: Computer vision and machine learning techniques can be used to select the most relevant and effective multimedia components to include in the presentation. For example, images and videos might be selected based on their relevance to the content and their visual impact.\n",
    "\n",
    "4. Multimedia arrangement: The selected multimedia components can be arranged and combined into a multimedia presentation using a variety of techniques, such as video editing software or presentation software.\n",
    "\n",
    "5. Output: The final output of the process is a multimedia presentation that effectively communicates the message or story to the intended audience.\n",
    "\n",
    "Multimedia presentation generation has many potential applications, including automated news reporting, educational content creation, and marketing and advertising."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Interfaces for intelligent tutoring system\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Interfaces for Intelligent Tutoring Systems (ITS) are designed to facilitate natural language communication between students and tutors. They are an essential part of modern ITS, as they allow students to ask questions and receive feedback in a more natural and intuitive way. Here are some short notes on language interfaces for intelligent tutoring systems:\n",
    "\n",
    "- Language interfaces for ITS are typically designed using natural language processing (NLP) techniques, such as text classification, named entity recognition, and semantic parsing.\n",
    "\n",
    "- One of the primary goals of language interfaces for ITS is to provide students with personalized feedback and support. This requires the system to be able to interpret and respond to the unique needs and characteristics of each individual student.\n",
    "\n",
    "- Another key feature of language interfaces for ITS is their ability to adapt to changes in the student's knowledge and skills over time. This requires the system to be able to track the student's progress and adjust its feedback and support accordingly.\n",
    "\n",
    "- Language interfaces for ITS can take many different forms, from simple chatbots to more sophisticated voice-activated assistants. The choice of interface depends on the specific needs and preferences of the students and the tutors.\n",
    "\n",
    "- Language interfaces for ITS can be used in a wide range of educational contexts, from traditional classroom settings to online and remote learning environments. They are particularly useful in situations where students need to learn complex concepts or skills that require personalized feedback and support.\n",
    "\n",
    "Concluding, language interfaces for ITS are an important tool for enhancing student learning and improving educational outcomes. They enable students to receive personalized feedback and support in a natural and intuitive way, which can help to improve their understanding and retention of key concepts and skills.\n",
    "\n",
    "This allows for a more inclusive educational experience for disabled people, providing accessibility to knowledge. Another example of how technology can change the lives of many in a drastic way, and try to level out the playing field for everyone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIRCSIM - Tutor\n",
    "---\n",
    "\n",
    "CIRCSIM-Tutor is an intelligent tutoring system designed to teach the principles of basic electronics and circuit analysis. It was developed at Carnegie Mellon University in the 1990s, and has been used in a variety of educational settings to help students learn about electrical circuits.\n",
    "\n",
    "CIRCSIM-Tutor is built around a circuit simulator that allows students to design and test electronic circuits in a virtual environment. The system provides feedback and guidance to help students understand the behavior of circuits and how to analyze them.\n",
    "\n",
    "One of the key features of CIRCSIM-Tutor is its ability to provide personalized feedback to students. The system tracks the student's progress and adapts its feedback and support to meet their individual needs. This helps to ensure that students receive the right level of guidance and support as they work through the material.\n",
    "\n",
    "CIRCSIM-Tutor is also designed to be user-friendly and accessible, with a simple interface that allows students to focus on the content rather than the technology. The system provides a range of instructional materials, including tutorials, examples, and practice problems, to help students learn at their own pace.\n",
    "\n",
    "Overall, CIRCSIM-Tutor is an effective tool for teaching the principles of basic electronics and circuit analysis. Its personalized feedback and guidance, along with its user-friendly interface and range of instructional materials, make it a valuable resource for students and educators alike."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTutor\n",
    "\n",
    "AutoTutor was sort of the successor to CIRCSIM, developed in the early noughties by the University of Memphis.\n",
    "\n",
    "AutoTutor is an intelligent tutoring system that uses natural language processing and machine learning techniques to simulate a conversation with a human tutor.\n",
    "\n",
    "AutoTutor works by engaging the student in a conversation and asking them questions about the material. The system uses natural language processing techniques to understand the student's responses and provide appropriate feedback and guidance. It also uses machine learning algorithms to adapt to the student's individual learning style and provide personalized support.\n",
    "\n",
    "One of the key features of AutoTutor is its ability to provide human-like interactions with the student. The system uses a conversational interface and can understand and respond to natural language inputs, making the learning experience more engaging and interactive.\n",
    "\n",
    "AutoTutor has been used to teach a range of subjects, including physics, computer science, and history. It has been shown to be an effective tool for improving student learning outcomes and engagement, and has the potential to be used in a wide range of educational settings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATLAS Andes\n",
    "\n",
    "ATLAS Andes was an intelligent tutoring system that aimed to improve students' problem-solving skills in the field of physics. It was developed at Arizona State University and designed to help students learn through interactive problem-solving exercises.\n",
    "\n",
    "ATLAS Andes uses a database of physics problems and associated solutions to create a personalized learning experience for each student. The system presents the student with a problem and asks them to solve it using the principles of physics. The student's responses are then analyzed, and the system provides feedback and guidance to help them improve their problem-solving skills.\n",
    "\n",
    "One of the key features of ATLAS Andes is its ability to adapt to the student's individual learning style and pace. The system uses machine learning algorithms to analyze the student's responses and determine their strengths and weaknesses. This allows the system to provide personalized feedback and guidance that is tailored to the student's needs.\n",
    "\n",
    "ATLAS Andes also includes a range of instructional materials, including tutorials and interactive simulations, to help students learn the principles of physics. The system is designed to be user-friendly and accessible, with a simple interface that allows students to focus on the content rather than the technology."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why2-ATLAS tutoring system\n",
    "\n",
    "Why2-ATLAS is a combination of two intelligent tutoring systems, why2 and ATLAS Andes. \n",
    "\n",
    "Why2 is a natural language based tutoring system developed at Carnegie Mellon University that engages students in a conversation about science concepts to help them learn more effectively. \n",
    "\n",
    "ATLAS Andes is an intelligent tutoring system that focuses on improving students' problem-solving skills in physics.\n",
    "\n",
    "By combining these two systems, Why2-ATLAS provided students with a more comprehensive and personalized learning experience. The system used natural language processing to engage students in a conversation about physics concepts, helping them to develop a deeper understanding of the material. It also used machine learning algorithms to adapt to each student's individual learning style and pace, providing personalized feedback and guidance that is tailored to their needs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthcare\n",
    "\n",
    "There have been a wide range of applications for NLP in the Healthcare industry, here are a few examples:\n",
    "\n",
    "Clinical documentation: NLP can be used to analyze and extract relevant information from clinical documents, such as medical records, discharge summaries, and progress notes. This helps to improve the accuracy and completeness of clinical documentation and can assist with clinical decision making.\n",
    "\n",
    "Clinical decision support: NLP can be used to analyze clinical data and provide decision support to healthcare providers. For example, NLP algorithms can be used to identify patients who may be at risk for certain conditions or to recommend appropriate treatments based on patient data.\n",
    "\n",
    "Patient monitoring: NLP can be used to monitor patient health and identify potential issues. For example, NLP can analyze electronic health records (EHRs) to identify patients who are at risk for readmission or to track patients' progress over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical Decision Support (CDS) System.\n",
    "\n",
    "Clinical decision support (CDS) systems are computer-based tools designed to assist healthcare providers with clinical decision making. CDS systems use patient-specific information to provide tailored recommendations, alerts, and reminders to help clinicians make more informed decisions about patient care. These systems can help to reduce medical errors, improve patient outcomes, and increase efficiency in healthcare delivery.\n",
    "\n",
    "CDS systems use a variety of technologies, including natural language processing (NLP), machine learning, and expert systems. They can be integrated into electronic health record (EHR) systems or other clinical information systems to provide real-time decision support to healthcare providers.\n",
    "\n",
    "Examples of CDS system applications include medication dosing recommendations, alerts for potential drug interactions, and reminders for preventive care interventions. These systems can also be used to support clinical pathways and best practice guidelines to ensure that patients receive appropriate and consistent care."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of a simple CDS System:\n",
    "\n",
    "This classifies a patient as normal or abnormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define the labels and the number of samples per label\n",
    "labels = [\"normal\", \"abnormal\"]\n",
    "num_samples = 100\n",
    "\n",
    "# Generate the dataset\n",
    "dataset = []\n",
    "for label in labels:\n",
    "    for i in range(num_samples):\n",
    "        # Generate a random sentence\n",
    "        sentence = \"The patient's test results are \" + label + \".\"\n",
    "        \n",
    "        # Append the sentence and label to the dataset\n",
    "        dataset.append((sentence, label))\n",
    "\n",
    "# Define a function to extract features from the text\n",
    "def extract_features(text):\n",
    "    features = {}\n",
    "    # Count the occurrences of each word in the text\n",
    "    for word in text.split():\n",
    "        features[word] = features.get(word, 0) + 1\n",
    "    return features\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "random.shuffle(dataset)\n",
    "train_data = dataset[:int(len(dataset)*0.8)]\n",
    "test_data = dataset[int(len(dataset)*0.8):]\n",
    "\n",
    "# Train a Naive Bayes classifier on the training data\n",
    "import nltk\n",
    "train_features = [(extract_features(text), label) for (text, label) in train_data]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "# Test the classifier on the testing data\n",
    "test_features = [(extract_features(text), label) for (text, label) in test_data]\n",
    "accuracy = nltk.classify.accuracy(classifier, test_features)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role of NLP in CDS, NLP-CDS\n",
    "\n",
    "Natural Language Processing (NLP) can play a crucial role in Clinical Decision Support (CDS) systems by enabling computers to analyze unstructured clinical text data such as medical records, discharge summaries, and progress notes. NLP algorithms can extract relevant clinical information from these unstructured sources and convert it into a structured format that can be used to support clinical decision making.\n",
    "\n",
    "NLP-CDS systems use a combination of NLP algorithms, machine learning, and other techniques to provide tailored recommendations, alerts, and reminders to healthcare providers based on patient-specific data. These systems can help to reduce errors, improve patient outcomes, and increase the efficiency of healthcare delivery."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "For various reasons, across various industries, due to the nature of the world we live in, where we have an incredible number of consumers, customers, and businesses; the need for these businesses to assess the opinions of their customers has increased, and as the technology has become more accessible, the applications have become more widespread."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difficulties in Sentiment Analysis:\n",
    "\n",
    "Here's a list of a few common problems faced in sentiment analysis:\n",
    "\n",
    "1. Ambiguity: Words and phrases can have multiple meanings, and their sentiment can vary depending on the context in which they are used. For example, the word \"sick\" can be used to describe both something that is unpleasant (e.g., \"That woman was sick in the head\") and something that is impressive (e.g., \"That trick was sick\").\n",
    "\n",
    "2. Sarcasm and irony: Texts can contain sarcasm, irony, or other forms of figurative language that can be difficult for sentiment analysis tools to interpret. For example, a tweet that says \"Thanks a lot\" can be sarcastic and actually mean the opposite.\n",
    "\n",
    "3. Negation: Negation can be difficult to handle in sentiment analysis because it can reverse the polarity of the sentiment. For example, the sentence \"The food was not bad\" actually means that the food was good.\n",
    "\n",
    "4. Domain-specific language: Sentiment analysis models trained on general language may not perform well on text that contains domain-specific language. For example, a model trained on movie reviews may not perform well on text related to healthcare.\n",
    "\n",
    "5. Data imbalance: In many datasets, one sentiment class may be more prevalent than the others, which can bias the model towards that class and reduce its accuracy on the other classes.\n",
    "\n",
    "6. Cultural and linguistic differences: Sentiment analysis tools may perform differently in different languages and cultures. Some languages have complex grammar and syntax, which can make sentiment analysis more challenging.\n",
    "\n",
    "Overcoming these difficulties requires careful consideration of the dataset and the specific context in which the sentiment analysis is being performed. It may also involve using specialized techniques, such as incorporating domain-specific language or training the model on data from multiple languages and cultures.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document level sentiment analysis:\n",
    "\n",
    "Document-level classification in sentiment analysis involves analyzing the sentiment expressed in a document as a whole. The goal is to classify the document into one of several pre-defined categories, such as positive, negative, or neutral.\n",
    "\n",
    "Document-level classification can be performed using a variety of machine learning algorithms, including Support Vector Machines (SVMs), Naive Bayes, and neural networks. The process typically involves the following steps:\n",
    "\n",
    "1. Data preprocessing: The text data in the document is preprocessed to remove noise, such as stop words, punctuations, and HTML tags. The text data is then converted into a numerical representation, such as a bag-of-words or TF-IDF matrix.\n",
    "\n",
    "2. Feature selection: The features used to represent the document are selected. This can include unigrams, bigrams, or n-grams. Other features can include part-of-speech tags or sentiment lexicons.\n",
    "\n",
    "3. Model training: A machine learning model is trained on a labeled dataset of documents. The model learns to map the features of the document to its corresponding sentiment label.\n",
    "\n",
    "4. Model evaluation: The performance of the trained model is evaluated on a separate test dataset. Common evaluation metrics include accuracy, precision, recall, and F1-score.\n",
    "\n",
    "5. Prediction: The trained model can be used to predict the sentiment of new, unlabeled documents.\n",
    "\n",
    "Document-level classification can be used in a variety of applications, such as analyzing product reviews, social media posts, and news articles. Important to keep in mind that it can be challenging to accurately capture the nuances of sentiment expressed in longer documents, such as articles or essays. This is because the sentiment expressed in different parts of the document may be complex and varied. Nonetheless, document-level classification remains an important tool for sentiment analysis in many domains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence level sentiment analysis:\n",
    "\n",
    "As the name suggests, in this method we try to map a sentiment to each sentence of a document, which is a more grassroot level, allowing us to identify sentiments expressed in different parts of the documents; and the variation throughout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicons in sentiment analysis:\n",
    "\n",
    "In sentiment analysis, the lexicon is a set of words which have a corresponding sentiment polarity assigned to them, i.e they sway the sentiment of the document/sentence. There are different types of lexicons, here are a few commonly used ones:\n",
    "\n",
    "1. Polarity lexicons: These lexicons consist of words that are labeled with their corresponding sentiment polarity, such as positive or negative. Examples include SentiWordNet, AFINN, and MPQA.\n",
    "\n",
    "2. Emotion lexicons: These lexicons consist of words that are labeled with their corresponding emotions, such as joy, anger, fear, or sadness. Examples include NRC Emotion Lexicon and WordEmotion.\n",
    "\n",
    "3. Domain-specific lexicons: These lexicons are tailored to specific domains, such as social media or product reviews, and contain words or phrases that are relevant to that domain. Examples include SentiStrength and SenticNet.\n",
    "\n",
    "Lexicons can be used in different ways for sentiment analysis, such as by counting the frequency of positive and negative words in a text, or by calculating the sentiment polarity of individual words and combining them to generate a sentiment score for the text as a whole. However, lexicons have limitations in terms of coverage, accuracy and domain specificity.\n",
    "\n",
    "In different contexts, different words may mean different levels of emotions, so according to the use case, they may need to be tweaked accoridngly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature based sentiment analysis\n",
    "\n",
    "Feature-based sentiment analysis is a type of sentiment analysis that identifies the sentiment expressed towards different aspects or features of a product, service, or entity. It involves analyzing individual words or phrases within a text and assigning a sentiment score to each one based on its polarity, i.e., positive, negative, or neutral.\n",
    "\n",
    "In feature-based sentiment analysis, the goal is to identify the features or attributes that are being talked about in a text, and then analyze the sentiment associated with each feature. This is done by first extracting the relevant features or attributes from the text, and then using a sentiment lexicon or machine learning model to determine the sentiment polarity for each feature.\n",
    "\n",
    "For example, if we are analyzing customer reviews for a restaurant, we might extract features such as the food quality, service, ambiance, and price. We would then analyze the sentiment associated with each feature separately, to get a more detailed understanding of the overall sentiment expressed in the reviews."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will show an implementation of a feature based sentiment analysis engine on randomly generated paragraphs using faker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Year open hour well thing. Determine always large give safe story '\n",
      "  'situation. Truth institution any defense interesting else her.',\n",
      "  5),\n",
      " ('Plant such successful contain. Way game thought animal tree add say song. '\n",
      "  'Various end foreign TV.',\n",
      "  5),\n",
      " ('Purpose sometimes move speak sure five animal. Debate goal six party '\n",
      "  'economy.',\n",
      "  5),\n",
      " ('With knowledge should art husband group start accept. Though beautiful '\n",
      "  'beyond who. Same he citizen top care set.',\n",
      "  4),\n",
      " ('Project case figure author why professor. Manage decision type capital deal '\n",
      "  'economic. Respond TV matter.',\n",
      "  5)]\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "reviews = []\n",
    "for i in range(100):\n",
    "    rating = random.randint(1, 5)\n",
    "    review = fake.paragraph()\n",
    "    reviews.append((review, rating))\n",
    "\n",
    "\n",
    "pprint(reviews[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review (rating 5): Year open hour well thing. Determine always large give safe story situation. Truth institution any defense interesting else her.\n",
      "Positive review (rating 5): Plant such successful contain. Way game thought animal tree add say song. Various end foreign TV.\n",
      "Positive review (rating 5): Purpose sometimes move speak sure five animal. Debate goal six party economy.\n",
      "Positive review (rating 4): With knowledge should art husband group start accept. Though beautiful beyond who. Same he citizen top care set.\n",
      "Positive review (rating 5): Project case figure author why professor. Manage decision type capital deal economic. Respond TV matter.\n",
      "Positive review (rating 4): Stock film section five. Meeting friend smile town involve.\n",
      "Positive review (rating 1): Model black experience finally big yes focus song. Indicate pass professional significant.\n",
      "Positive review (rating 2): Site fill government keep business. Camera billion cultural always entire.\n",
      "Neutral review (rating 3): Market draw knowledge price door. Song shoulder sometimes.\n",
      "Negative review (rating 3): His beat western down floor front single. Skin speech toward.\n",
      "Negative review (rating 5): Soon sister order least morning. Seek start citizen. Read professional list. Ahead environmental personal direction open one.\n",
      "Positive review (rating 5): Free friend might matter radio national office. Outside table describe report exist. Wall TV race really buy whole.\n",
      "Positive review (rating 3): Focus before outside plant. Media one choice lead step. Pick marriage leg but firm fine expert.\n",
      "Positive review (rating 3): Home system international staff health. Oil treat special. Without since painting radio do. Miss operation ten rather bag.\n",
      "Negative review (rating 1): That center around wind article dream. Girl cold understand most. Contain effort not them project western animal student.\n",
      "Negative review (rating 1): Single sign design itself. Participant fall me may sit appear drop order. Support minute carry list. Though group attack eat.\n",
      "Positive review (rating 3): Sometimes learn watch through sense sound under. Strong chair anything hot. Part other manager east tax.\n",
      "Positive review (rating 4): Address environmental be during mission full. Car prevent save player thing worry news laugh.\n",
      "Neutral review (rating 2): Into include seat experience. Process situation sit meeting know consider. Evidence possible ahead provide method. Study various role treatment around.\n",
      "Positive review (rating 1): Apply later sound just interest throughout cold. Prepare top pick read.\n",
      "Positive review (rating 2): Everything old option price player. Let conference way detail maybe. Stuff fire analysis action last child single.\n",
      "Negative review (rating 2): Time number feel bed character fine. Answer difficult western pass trade.\n",
      "Negative review (rating 5): Around dark player base style career window. Market fine simple senior.\n",
      "Neutral review (rating 3): Song serve expect recent of cut. His security show. Education democratic ask mother deep.\n",
      "Positive review (rating 1): Region group believe. Involve defense market moment institution material impact new.\n",
      "Negative review (rating 2): The site spend may expect general compare artist. Bad degree message prepare. Front build song somebody movie.\n",
      "Negative review (rating 3): Food subject practice suffer.\n",
      "Negative review (rating 3): Require debate account although other area break. Can all note operation because dream. Guess everything life think entire change.\n",
      "Neutral review (rating 3): Work discuss news explain happen quite. Discussion ask different audience may.\n",
      "Positive review (rating 2): Just increase available suddenly natural morning nice go. Range dream likely way man road. Choose argue language myself.\n",
      "Positive review (rating 5): Support success draw win civil action more value. Game ball seat ready difference really avoid south. Parent employee mother officer event exist.\n",
      "Positive review (rating 4): Stuff tonight success science parent Republican. Like security fall cost.\n",
      "Negative review (rating 2): Especially policy recent modern culture everyone drive control. Mean law manager. Relationship whom reach church.\n",
      "Negative review (rating 3): Necessary mean rise consumer above only. International big stuff company partner. Perhaps western paper avoid.\n",
      "Positive review (rating 4): Argue room how under piece my. Alone security almost particular air wall rich.\n",
      "Positive review (rating 4): Again reduce without class enough record draw. Oil push morning public. Common firm rich edge about hear ready argue.\n",
      "Neutral review (rating 5): Response ground risk stuff amount discuss information drive. Bill store front ability. Phone structure someone station appear call.\n",
      "Positive review (rating 1): Ok race relate culture. They site report take.\n",
      "Positive review (rating 4): Price nice card detail brother save. Hit natural picture benefit message somebody today. After energy stuff agree cell.\n",
      "Positive review (rating 5): Choice city two thousand whole all democratic somebody. Environment although perhaps attorney charge.\n",
      "Positive review (rating 4): Century government address none clearly. Skin future sometimes teach save cultural life stop. Central country bed road. Operation ago edge success or shoulder popular ago.\n",
      "Positive review (rating 4): Process them possible red apply ok test. Professional president ok visit. Heavy certainly address all third.\n",
      "Positive review (rating 2): Generation third base top data marriage. Significant attorney police on majority key picture.\n",
      "Neutral review (rating 3): Together serve tend. Actually drop strategy western husband total training.\n",
      "Neutral review (rating 5): Item study list prevent stand medical. Military food walk management early environment. Visit too people growth.\n",
      "Neutral review (rating 3): Color court enter bring admit. Believe which dinner. For age away sense mind know war.\n",
      "Neutral review (rating 3): List his unit together view. Me garden protect.\n",
      "Positive review (rating 3): Then manage this able commercial animal own. Over difficult financial dream even special. Yard become cultural ahead onto. Should citizen although common wide.\n",
      "Neutral review (rating 5): Everyone stop personal occur end. Heart miss sea establish weight rock.\n",
      "Negative review (rating 3): Cut summer call money reveal employee property energy. Business wide store book camera owner.\n",
      "Neutral review (rating 5): Than listen pressure loss industry movie. Owner listen item he but ahead responsibility language.\n",
      "Positive review (rating 4): Activity whatever job market anyone nice range. Station who high.\n",
      "Negative review (rating 4): Effect want nation establish page. Author idea catch party. Than security hope once possible small will.\n",
      "Positive review (rating 1): Thousand from three agreement star. Great soon agent list support here position. Day across measure music back election simple.\n",
      "Positive review (rating 5): Generation put race picture. Sure boy present Congress. Night hope pretty simply.\n",
      "Neutral review (rating 3): Its take current million suddenly community stand. Movie occur what visit sit majority task. Level case recent off.\n",
      "Positive review (rating 4): Attention most often. Hundred beautiful live yet discussion. Environment last better rather music such.\n",
      "Positive review (rating 4): Car protect his mean attack fall store business. Officer woman research pretty consumer. Rich type coach option less speech factor market.\n",
      "Positive review (rating 2): Long go record friend. Position including one record. Audience today exactly collection body family.\n",
      "Negative review (rating 4): Upon nation begin usually of. Effort property too sister in. Pm citizen head off parent out.\n",
      "Neutral review (rating 4): Seat break draw find since north opportunity gun.\n",
      "Positive review (rating 3): Stop treatment red conference first possible. Mother worker analysis rock. Relationship chair necessary gun window moment.\n",
      "Neutral review (rating 1): Sell box fear both candidate. Create feel show society what animal.\n",
      "Positive review (rating 5): Wide inside major build whole size. Safe lead eye white research about. Behavior business color he.\n",
      "Neutral review (rating 2): Yard your rather series.\n",
      "Neutral review (rating 2): Wonder low building war.\n",
      "Positive review (rating 5): Network once true hotel age suddenly. Land probably imagine whether choose nature. Civil leader hear stop interview model order. Power author student bring include moment.\n",
      "Positive review (rating 5): Way authority and early. Or indicate participant significant music. Performance whatever first other environment.\n",
      "Positive review (rating 3): Similar light next music voice read moment. Room mouth huge through into until power address.\n",
      "Neutral review (rating 2): Lay receive center nearly use. Movie admit list same option school ability.\n",
      "Positive review (rating 2): Memory phone major standard stage kitchen. Tv hear check around travel represent.\n",
      "Neutral review (rating 1): Measure learn already send. Task training step walk occur scientist.\n",
      "Positive review (rating 5): My finally like reflect become. Know property top reality drug. Arm from structure.\n",
      "Negative review (rating 2): Health task common treatment score. There economic whom.\n",
      "Positive review (rating 3): Reality cut sister PM size. Require just church space degree film camera. Weight five best specific particular idea.\n",
      "Positive review (rating 5): What deal performance cultural political stuff. Bag southern interest science economy. Discover control fact go true add ago. Pick American buy suffer program natural.\n",
      "Positive review (rating 4): Federal power stop about college manage. Available serious call then. One red safe beautiful fish chair kitchen.\n",
      "Positive review (rating 4): Music economic most local leader some. Edge degree morning view store until certain leader. Then value local many view history bad.\n",
      "Neutral review (rating 4): Child look him address line anything. Tree player different while nature.\n",
      "Positive review (rating 3): Draw else agree carry. Live conference adult court.\n",
      "Positive review (rating 2): Own husband black alone. Cultural property painting. Space interest town specific decision season.\n",
      "Positive review (rating 3): Expert board assume seem. Opportunity onto us line police fear. Probably seem lot seek make wind. Goal good walk particular without this piece company.\n",
      "Positive review (rating 1): Help language end might over deep whatever special. Ten usually something man. Card size oil as.\n",
      "Negative review (rating 4): Rise fear natural late increase family song might. Age really heavy manager. Whatever energy girl onto whether cost.\n",
      "Neutral review (rating 1): Cover three too computer Republican perhaps pull example. Risk office visit capital mission go bring.\n",
      "Positive review (rating 2): Court you baby spend office. Act clear prevent attack call reflect key. Happy expect field alone democratic. Spend section show budget condition.\n",
      "Neutral review (rating 3): Measure however network deep study. Two field gun.\n",
      "Positive review (rating 1): Still which sing report worker place sea. Audience he owner example nothing government skill adult.\n",
      "Positive review (rating 4): Whom admit discover. Road interesting hit inside dark foreign.\n",
      "Positive review (rating 3): Anyone peace whom maybe Republican near risk. Every nearly money direction you hand road old. Head pick finish read.\n",
      "Positive review (rating 5): Generation value guy hour cultural factor. Reduce music whole evidence manage. Boy face option herself.\n",
      "Neutral review (rating 1): Before yet believe beyond home tax above.\n",
      "Positive review (rating 1): They personal range produce character. No of you. Certainly air per production wall. President up spring fact.\n",
      "Positive review (rating 5): Off true positive treat improve watch film.\n",
      "Positive review (rating 3): Cell fill method wife arrive maintain gun. Candidate kitchen plant bad boy again laugh. Company happy check short clearly already.\n",
      "Positive review (rating 2): Build condition society personal surface spend teach. Imagine international professional follow.\n",
      "Negative review (rating 4): One suddenly end level. Pay and short service support rule. Military hold fish ago eight anyone.\n",
      "Positive review (rating 3): Behind push investment eye develop some crime. New improve soldier measure role herself issue field. Safe ready any stage.\n",
      "Positive review (rating 5): Cost seem those budget pass personal own. Effect support loss among play kind rise.\n",
      "Neutral review (rating 1): Group improve television.\n",
      "[0.3035714285714286, 0.045, 0.5, 0.45, 0.2, 0.3, 0.07708333333333334, 0.05, 0.0, -0.07566137566137567, -0.049999999999999996, 0.2, 0.07222222222222223, 0.11904761904761905, -0.04999999999999999, -0.07142857142857142, 0.23958333333333331, 0.32499999999999996, 0.0, 0.07500000000000001, 0.03214285714285715, -0.027777777777777773, -0.13333333333333336, 0.0, 0.13636363636363635, -0.3249999999999999, -0.16666666666666666, -0.0625, 0.0, 0.275, 0.24285714285714288, 0.3, -0.028124999999999997, -0.044642857142857144, 0.2708333333333333, 0.012500000000000002, 0.0, 0.5, 0.35, 0.2, 0.18333333333333335, 0.1392857142857143, 0.01499999999999999, 0.0, 0.0, 0.0, 0.0, 0.07301587301587303, 0.0, -0.1, 0.0, 0.38, -0.125, 0.26666666666666666, 0.1875, 0.0, 0.33106060606060606, 0.036458333333333336, 0.1, -0.25, 0.0, 0.0625, 0.0, 0.1325, 0.0, 0.0, 0.175, 0.15, 0.2, 0.0, 0.03125, 0.0, 0.25, -0.04999999999999999, 0.3888888888888889, 0.09166666666666666, 0.2833333333333333, 0.10204081632653061, 0.0, 0.11818181818181818, 0.13333333333333333, 0.4333333333333333, 0.026785714285714288, -0.13333333333333333, 0.0, 0.3, 0.0, 0.1, 0.075, 0.10000000000000002, 0.15000000000000002, 0.0, 0.10714285714285714, 0.28863636363636364, 0.10000000000000005, 0.03333333333333333, -0.03333333333333333, 0.10909090909090909, 0.39999999999999997, 0.0]\n",
      "0.09603740551776267\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "polarities = []\n",
    "\n",
    "for review, rating in reviews:\n",
    "    blob = TextBlob(review)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        print(f\"Positive review (rating {rating}): {review}\")\n",
    "    elif polarity < 0:\n",
    "        print(f\"Negative review (rating {rating}): {review}\")\n",
    "    else:\n",
    "        print(f\"Neutral review (rating {rating}): {review}\")\n",
    "    polarities.append(polarity)\n",
    "    \n",
    "print(polarities)\n",
    "print(np.mean(polarities))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinion Summarization:\n",
    "\n",
    "Opinion summarization is a text summarization task that focuses on extracting the main opinions and sentiments expressed in a large set of reviews or opinions on a given topic. The goal is to generate a concise summary of the key opinions and sentiments expressed in the reviews or opinions.\n",
    "\n",
    "Opinion summarization is typically done by first identifying the main aspects or features being discussed in the reviews, and then extracting the sentiment expressed for each aspect. The sentiments can be classified as positive, negative, or neutral. Once all the sentiments have been extracted, they are typically aggregated to generate an overall sentiment score for the topic.\n",
    "\n",
    "Opinion summarization has applications in a variety of areas, including market research, product development, and customer service. It can help companies quickly identify the strengths and weaknesses of their products and services, and make data-driven decisions based on customer feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
