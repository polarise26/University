{"cells":[{"cell_type":"markdown","metadata":{"id":"JpeCXe7ZPZFh"},"source":["## Experiment 6 - Applying Word2Vec model."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1676887595793,"user":{"displayName":"K T","userId":"07195030322707032289"},"user_tz":-330},"id":"_4mTaKrxX_Cu","outputId":"af1d31a2-5c7d-4ee1-ddb5-3cbef19d3d2b"},"outputs":[],"source":["import nltk\n","import re\n","import pandas as pd\n","import tweepy\n","\n","from gensim.models import Word2Vec\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from gensim.models import Word2Vec as w2v\n","from pprint import pprint"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ck0FZ9cjYpE4"},"outputs":[],"source":["client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAABmPlQEAAAAA%2BwLAFFHUHJoloCwUtx3LRUne7ow%3DUuxTLzdbr7VEZvSUj1dO3gDreYZ6XCVMbe1wxwjOqkFbNw1VhQ')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zU1_MsVP0UfA"},"outputs":[],"source":["query = 'from:NBA -is:retweet'      # Gives us the tweets from the official NBA account, that isn't a retweet. \n","tweets = client.search_recent_tweets(query=query, tweet_fields=['context_annotations', 'created_at'], max_results = 50)\n","twtList = []"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TQkfEOWR0XUf"},"outputs":[],"source":["for i, tweet in enumerate(tweets.data):\n","  twtList.append(tweet.text)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"NFd9OX04Ysur"},"outputs":[],"source":["ps = PorterStemmer()\n","wordNet = WordNetLemmatizer()\n","corpus = []"]},{"cell_type":"markdown","metadata":{"id":"O_pJSTxKJiJq"},"source":["Here, I loop through the sentences within our paragraph (as I have tokenized by sentence, and not word) and perform the following preprocessing tasks:\n","\n","1. Removing any link in the tweet, as that was very common.\n","2. Removing \"\\n\"'s which were also pretty common.\n","1. Converting the sentence to lowercase.\n","2. Removing all characters that are not a part of the Latin script.\n","3. Splitting the sentence into an array of words.\n","4. Applying Porter's Stemming Algorithm to each word in the sentence, that isnt a stopword.\n","5. Adding a space at the end to make sure there's a space in between each word."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"OjMfyCpTZZjI"},"outputs":[],"source":["for i in range (len(twtList)):\n","  review = re.sub(r\"http\\S+\", \"\", twtList[i])\n","  review = re.sub('\\n', ' ', review)\n","  review = re.sub('[^a-zA-Z]', ' ', review)\n","  review = review.lower()\n","  review = review.split()\n","  review = [word for word in review if word not in set(stopwords.words('english'))]\n","  review = [ps.stem(word) for word in review]\n","  review = ' '.join(review)\n","  corpus.append(review)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['four', 'nyknick', 'player', 'score', 'first', 'time', 'sinc', 'qdotgrim', 'pt', 'jalenbrunson', 'pt', 'iq', 'godson', 'pt', 'obitoppin', 'pt', 'nyk', 'clinch', 'spot', 'nbaplayoff', 'present', 'googl', 'pixel'], ['donovan', 'mitchel', 'becom', 'first', 'player', 'cav', 'histori', 'straight', 'point', 'game', 'cle', 'win', 'home', 'dariu', 'garland', 'pt', 'evan', 'mobley', 'pt', 'reb', 'blk', 'cari', 'levert', 'pt', 'blk', 'jarrett', 'allen', 'pt', 'download', 'nba', 'app'], ['michael', 'porter', 'jr', 'jamal', 'murray', 'west', 'lead', 'nugget', 'improv', 'home', 'murray', 'pt', 'ast', 'stl', 'blk', 'bruce', 'brown', 'pt', 'stl', 'aaron', 'gordon', 'pt', 'reb', 'ast', 'stl', 'download', 'nba', 'app'], ['anoth', 'look', 'emphat', 'peyton', 'watson', 'three', 'block', 'tonight'], ['peytonwatson', 'talk', 'special', 'block', 'tonight', 'nugget', 'win'], ['gianni', 'antetokounmpo', 'goe', 'floor', 'buck', 'score', 'plu', 'win', 'vs', 'phi', 'brook', 'lopez', 'pt', 'fgm', 'khri', 'middleton', 'pt', 'ast', 'jrue', 'holiday', 'pt', 'stl', 'bobbi', 'porti', 'pt', 'fgm', 'download', 'nba', 'app'], ['kd', 'drop', 'okc', 'sun', 'win', 'th', 'row', 'devin', 'booker', 'pt', 'ast', 'deandr', 'ayton', 'pt', 'reb', 'chri', 'paul', 'pt', 'ast', 'shai', 'gilgeou', 'alexand', 'pt', 'download', 'nba', 'app'], ['gianni', 'domin', 'tonight', 'buck', 'got', 'nba', 'best', 'th', 'win', 'pt', 'fgm', 'reb', 'ast', 'blk'], ['ad', 'goe', 'field', 'lebron', 'drop', 'tripl', 'doubl', 'laker', 'win', 'th', 'time', 'game', 'lbj', 'pt', 'reb', 'ast', 'austin', 'reav', 'pt', 'ast', 'rui', 'hachimura', 'pt', 'reb', 'blk', 'download', 'nba', 'app'], ['player', 'reach', 'doubl', 'figur', 'orlandomag', 'w', 'jalen', 'sugg', 'pt', 'stl', 'cole', 'anthoni', 'pt', 'franz', 'wagner', 'pt', 'ast', 'stl', 'paolo', 'banchero', 'pt', 'goga', 'bitadz', 'pt', 'mo', 'wagner', 'amp', 'markel', 'fultz', 'pt', 'download', 'nba', 'app'], ['donovan', 'mitchel', 'drop', 'third', 'straight', 'game', 'incred', 'season', 'continu', 'cav', 'get', 'win'], ['trae', 'young', 'atlhawk', 'outlast', 'dalla', 'ot', 'thriller', 'dejount', 'murray', 'pt', 'john', 'collin', 'pt', 'reb', 'clint', 'capela', 'pt', 'reb', 'kyri', 'irv', 'pt', 'download', 'nba', 'app'], ['sequenc', 'end', 'warrior', 'nugget', 'jamal', 'murray', 'huge', 'block', 'seal', 'den', 'win'], ['klay', 'wild', 'tripl', 'cut', 'left', 'nbatv'], ['acrobat', 'finish', 'big', 'slam', 'peyton', 'watson', 'provid', 'energi', 'nugget', 'th', 'quarter', 'surg', 'lead', 'late', 'nba', 'tv'], ['jamal', 'murray', 'heat', 'q', 'nbatv', 'nugget', 'warrior'], ['sga', 'kd', 'battl', 'okc', 'tonight', 'shaiglalex', 'pt', 'kdtrey', 'pt', 'w'], ['lebron', 'jame', 'tie', 'jason', 'kidd', 'th', 'tripl', 'doubl', 'ever', 'pt', 'reb', 'ast', 'laker'], ['point', 'anthoni', 'davi', 'fgm', 'th', 'win', 'game', 'lal', 'antdavi', 'lead', 'charg', 'laker', 'keep', 'pace', 'pack', 'western', 'confer'], ['draymond', 'steal', 'draymond', 'outlet', 'klay', 'cut', 'curri', 'dime', 'klay', 'finish', 'decad', 'warrior', 'lead', 'den', 'halftim', 'nbatv'], ['dariu', 'garland', 'look', 'jarrett', 'allen', 'cav', 'lead', 'pacer', 'q'], ['julian', 'champagni', 'goe', 'career', 'high', 'spur', 'top', 'sacramento', 'ot', 'doug', 'mcdermott', 'pt', 'tre', 'jone', 'pt', 'reb', 'ast', 'download', 'nba', 'app'], ['quentin', 'grime', 'nyknick', 'go', 'point', 'nyk', 'clinch', 'spot', 'nbaplayoff', 'present', 'googl', 'pixel', 'jalen', 'brunson', 'pt', 'ast', 'immanuel', 'quickley', 'pt', 'stl', 'obi', 'toppin', 'pt', 'stl', 'download', 'nba', 'app'], ['ad', 'buri', 'j', 'point', 'watch', 'nba', 'app'], ['trae', 'young', 'knock', 'pair', 'clutch', 'free', 'throw', 'hawk', 'left', 'ot', 'dalla', 'ball', 'nba', 'tv'], ['kyri', 'tie', 'got', 'final', 'second', 'ot', 'nbatv'], ['javal', 'tie', 'ft', 'line', 'dallasmav', 'atlhawk', 'left', 'nba', 'tv'], ['de', 'aaron', 'fox', 'thing', 'clutch', 'tough', 'jumper', 'forc', 'ot', 'watch', 'nba', 'app'], ['kyri', 'take', 'tie', 'game', 'reach', 'point', 'second', 'left', 'get', 'nba', 'app'], ['point', 'ad', 'assist', 'lbj', 'halftim', 'watch', 'live', 'nba', 'app'], ['obi', 'toppin', 'make', 'play', 'end', 'knick', 'clinch', 'spot', 'nbaplayoff', 'present', 'googl', 'pixel', 'win', 'nba', 'app'], ['alpi', 'unbeliev'], ['alperen', 'sengun', 'half', 'spin', 'watch', 'nba', 'app'], ['tough', 'okongwu', 'atl', 'dal', 'tight', 'enter', 'q', 'nbatv'], ['austin', 'reav', 'deep', 'bag', 'watch', 'live', 'nba', 'app'], ['doma', 'drive', 'purpos', 'watch', 'live', 'nba', 'app'], ['trae', 'save', 'bey', 'trey', 'bey', 'pick', 'trae', 'hawk', 'lead', 'dal', 'late', 'q'], ['joel', 'embiid', 'arriv', 'phantomcam', 'vs', 'east', 'sixer', 'buck', 'pm', 'et', 'nba', 'app'], ['jerom', 'betti', 'courtsid', 'atlanta', 'nbacelebrow'], ['adjust', 'hangtim', 'english', 'kyri', 'thing'], ['kyri', 'shot', 'make', 'savant', 'shoot', 'watch', 'nba', 'app'], ['brunson', 'clear', 'path', 'rim', 'sick', 'dribbl', 'nyk', 'seek', 'playoff', 'spot'], ['two', 'bull', 'drop', 'piec', 'comeback', 'w', 'lavin', 'pt', 'ast', 'derozan', 'pt', 'reb', 'ast'], ['mikal', 'bridg', 'score', 'lead', 'brooklynnet', 'home', 'win', 'tht', 'pt', 'reb', 'ast', 'download', 'nba', 'app'], ['obi', 'go', 'top', 'earli', 'often', 'nyknick', 'clinch', 'playoff', 'spot', 'win', 'watch', 'nba', 'app'], ['three', 'straight', 'point', 'game', 'shaedon', 'sharp', 'today', 'pt', 'reb', 'ast', 'w', 'first', 'blazer', 'rooki', 'sinc', 'kelvin', 'ransey'], ['shaedon', 'sharp', 'becam', 'first', 'trailblaz', 'rooki', 'sinc', 'kelvin', 'ransey', 'drop', 'three', 'straight', 'point', 'game', 'pick', 'road', 'w', 'ant', 'edward', 'pt', 'reb', 'ast', 'download', 'nba', 'app'], ['zach', 'lavin', 'drop', 'lead', 'chicagobul', 'comeback', 'w', 'home', 'demar', 'derozan', 'pt', 'reb', 'ast', 'jjj', 'pt', 'reb', 'pm', 'ja', 'morant', 'pt', 'reb', 'ast', 'download', 'nba', 'app'], ['mikal', 'bridg', 'pt', 'extend', 'brooklyn', 'lead', 'crunchtim', 'remain', 'watch', 'live', 'nba', 'app'], ['final', 'score', 'thread', 'fred', 'vanvleet', 'broke', 'raptor', 'singl', 'game', 'assist', 'record', 'today', 'becom', 'nd', 'undraft', 'player', 'nba', 'histori', 'drop', 'game', 'pascal', 'siakam', 'pt', 'reb', 'ast', 'download', 'nba', 'app']]\n","50\n"]}],"source":["words = [nltk.word_tokenize(tweet) for tweet in corpus]\n","print(words)\n","print(len(words))"]},{"cell_type":"markdown","metadata":{},"source":["We're creating a Word2Vec object over the corpus, which only considers words appearing at least twice."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["w2v = Word2Vec(words, min_count = 2)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['pt', 'nba', 'app', 'ast', 'reb', 'download', 'win', 'lead', 'game', 'watch', 'stl', 'point', 'drop', 'w', 'th', 'nbatv', 'blk', 'murray', 'spot', 'nugget', 'ot', 'kyri', 'left', 'fgm', 'tonight', 'q', 'tie', 'trae', 'clinch', 'live', 'straight', 'player', 'score', 'first', 'home', 'buck', 'doubl', 'tripl', 'ad', 'sinc', 'nyk', 'jamal', 'goe', 'nbaplayoff', 'present', 'block', 'three', 'googl', 'pixel', 'cav', 'laker', 'nyknick', 'obi', 'tv', 'warrior', 'klay', 'jarrett', 'final', 'second', 'garland', 'dariu', 'bey', 'tough', 'allen', 'assist', 'make', 'dal', 'histori', 'hawk', 'thing', 'wagner', 'clutch', 'mikal', 'rooki', 'today', 'sharp', 'time', 'shaedon', 'bridg', 'derozan', 'mitchel', 'lavin', 'comeback', 'playoff', 'pm', 'pick', 'donovan', 'becom', 'brunson', 'toppin', 'anthoni', 'jalen', 'get', 'reach', 'reav', 'austin', 'lbj', 'kelvin', 'young', 'atlhawk', 'lebron', 'dalla', 'got', 'end', 'okc', 'kd', 'den', 'vs', 'cut', 'gianni', 'finish', 'late', 'watson', 'peyton', 'look', 'aaron', 'draymond', 'halftim', 'top', 'go', 'ransey']\n","121\n"]}],"source":["vocabW2V = w2v.wv.index_to_key\n","print(vocabW2V)\n","print(len(vocabW2V))"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, we have formed our W2V model on the tweets extracted. Now, we can look for representations of the different words in our model:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 0.00666689 -0.00881539 -0.00727956 -0.00174794  0.00166154 -0.00144057\n"," -0.00493048  0.00724126  0.00863624 -0.00767355  0.00967828  0.00698259\n"," -0.00745818 -0.00175638  0.0043967   0.00701735 -0.00375165 -0.0072367\n","  0.00464955 -0.00961711 -0.00559149 -0.00128195  0.00556314 -0.00599434\n","  0.00468193 -0.00052743  0.00254426  0.00620476  0.00107827  0.00762274\n"," -0.00028078 -0.00818851  0.00958006 -0.00515526  0.00457158 -0.00363335\n"," -0.00719431 -0.00686334  0.00447483 -0.00099204  0.00155827 -0.00910584\n"," -0.00534432 -0.00609037  0.00872603 -0.00878718  0.00484827 -0.00109544\n","  0.00052954  0.00898639 -0.00358033 -0.00707362  0.00082357  0.00761332\n","  0.00932517 -0.00348077  0.00271011  0.00495672 -0.00560967  0.00689182\n"," -0.00633227  0.00206102  0.00469636  0.00443209 -0.00491915  0.00304871\n","  0.00740371  0.00883198 -0.00989856  0.00585175  0.0048487  -0.00143654\n","  0.00943001 -0.00422003 -0.00137997 -0.00677631 -0.00349633  0.00017042\n"," -0.0034795  -0.00530531  0.00661963 -0.0053038  -0.00670166  0.00822232\n","  0.00930523  0.00393319  0.00046951  0.00107228 -0.00061555  0.00698952\n"," -0.00589767  0.00076381  0.00433958 -0.00210234  0.00117844  0.00386212\n","  0.00963827  0.00224726  0.00964595 -0.0059287 ]\n","100\n"]}],"source":["print(w2v.wv['score'])\n","print(len(w2v.wv['score']))\n"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, the, in our model, the word 'score' is stored as 100 dimensional vector (default argument for the model).  \n","\n","So, we are embedding (or representing) each word in the vocabulary to a 100-dimensional vectors, having features from [-1, 1]."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNu/3C8KjV63D2HKlbMzrtq","provenance":[{"file_id":"1n1H7GmqI2cj4JR8rppKjBvf3OpBQmaS0","timestamp":1676887660920},{"file_id":"1SU8qxaXW2suJdcM4RkalH4FGkq57lcLW","timestamp":1676885439423},{"file_id":"17D7PeMaapKqB7_ek6RV2HfHdzH1OSByj","timestamp":1676866185654}]},"kernelspec":{"display_name":"Python 3.9.13 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"661c601753f4483e8dd0b9e1edc43929dfff6a17812d9109dd50ebc376d0b41d"}}},"nbformat":4,"nbformat_minor":0}
